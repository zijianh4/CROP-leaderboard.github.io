<table id="CartPole-v0_leaderboard_GRe-median" class="datatable" style="width: 100%">
    <thead>
    <tr>
        <th class="rank">Rank</th>
        <th class="method">Method</th>
        <th class="sigma_e-3">
            &sigma; = 0.001
        </th>
        
        
        <th class="sigma_5e-3">
            &sigma; = 0.005
        </th>
        
        <th class="sigma_1e-2">&sigma; = 0.01</th>
        <th class="sigma_3e-2">&sigma; = 0.03</th>
        <th class="sigma_5e-2">&sigma; = 0.05</th>
        <th class="sigma_1e-1">&sigma; = 0.1</th>
    </tr>
    </thead>
    <tbody>
    
    <tr>
        <td class="ranktd">1</td>
        <td class="methoddt">
            <a href="https://arxiv.org/abs/2004.06496" target="_blank">Certifiable Robustness to Adversarial State Uncertainty in Deep Reinforcement Learning</a>
            
        </td>
        <td class="catd"><img src='./CartPole-v0/images/figs_0911_CartPole_global_median_CARRL/CartPole_global_median_sigma-0.001_cmp.pdf'></td>
        <td class="aatd"><img src='./CartPole-v0/images/figs_0911_CartPole_global_median_CARRL/CartPole_global_median_sigma-0.005_cmp.pdf'></td>
        
        <td class="datatd"><img src='./CartPole-v0/images/figs_0911_CartPole_global_median_CARRL/CartPole_global_median_sigma-0.01_cmp.pdf'></td>
        <td class="archtd"><img src='./CartPole-v0/images/figs_0911_CartPole_global_median_CARRL/CartPole_global_median_sigma-0.03_cmp.pdf'></td>
        <td class="venuetd"><img src='./CartPole-v0/images/figs_0911_CartPole_global_median_CARRL/CartPole_global_median_sigma-0.05_cmp.pdf'></td>
        <td class="venuetd_2"><img src='./CartPole-v0/images/figs_0911_CartPole_global_median_CARRL/CartPole_global_median_sigma-0.1_cmp.pdf'></td>
    </tr>
    
    <tr>
        <td class="ranktd">2</td>
        <td class="methoddt">
            <a href="https://arxiv.org/abs/2008.01976" target="_blank">Robust Deep Reinforcement Learning through Adversarial Loss</a>
            
        </td>
        <td class="catd"><img src='./CartPole-v0/images/figs_0911_CartPole_global_median_RadialRL/CartPole_global_median_sigma-0.001_cmp.pdf'></td>
        <td class="aatd"><img src='./CartPole-v0/images/figs_0911_CartPole_global_median_RadialRL/CartPole_global_median_sigma-0.005_cmp.pdf'></td>
        
        <td class="datatd"><img src='./CartPole-v0/images/figs_0911_CartPole_global_median_RadialRL/CartPole_global_median_sigma-0.01_cmp.pdf'></td>
        <td class="archtd"><img src='./CartPole-v0/images/figs_0911_CartPole_global_median_RadialRL/CartPole_global_median_sigma-0.03_cmp.pdf'></td>
        <td class="venuetd"><img src='./CartPole-v0/images/figs_0911_CartPole_global_median_RadialRL/CartPole_global_median_sigma-0.05_cmp.pdf'></td>
        <td class="venuetd_2"><img src='./CartPole-v0/images/figs_0911_CartPole_global_median_RadialRL/CartPole_global_median_sigma-0.1_cmp.pdf'></td>
    </tr>
    
    <tr>
        <td class="ranktd">3</td>
        <td class="methoddt">
            <a href="https://arxiv.org/abs/1312.5602" target="_blank">Playing Atari with Deep Reinforcement Learning</a>
            
        </td>
        <td class="catd"><img src='./CartPole-v0/images/figs_0911_CartPole_global_median_StdTrain/CartPole_global_median_sigma-0.001_cmp.pdf'></td>
        <td class="aatd"><img src='./CartPole-v0/images/figs_0911_CartPole_global_median_StdTrain/CartPole_global_median_sigma-0.005_cmp.pdf'></td>
        
        <td class="datatd"><img src='./CartPole-v0/images/figs_0911_CartPole_global_median_StdTrain/CartPole_global_median_sigma-0.01_cmp.pdf'></td>
        <td class="archtd"><img src='./CartPole-v0/images/figs_0911_CartPole_global_median_StdTrain/CartPole_global_median_sigma-0.03_cmp.pdf'></td>
        <td class="venuetd"><img src='./CartPole-v0/images/figs_0911_CartPole_global_median_StdTrain/CartPole_global_median_sigma-0.05_cmp.pdf'></td>
        <td class="venuetd_2"><img src='./CartPole-v0/images/figs_0911_CartPole_global_median_StdTrain/CartPole_global_median_sigma-0.1_cmp.pdf'></td>
    </tr>
    
    <tr>
        <td class="ranktd">4</td>
        <td class="methoddt">
            <a href="https://arxiv.org/abs/1712.09344" target="_blank">Whatever Does Not Kill Deep Reinforcement Learning, Makes It Stronger</a>

            <br>
            <span class="td-footer">
                Trained with Gaussian augmentation states.
            </span>
            
        </td>
        <td class="catd"><img src='./CartPole-v0/images/figs_0911_CartPole_global_median_GaussAug/CartPole_global_median_sigma-0.001_cmp.pdf'></td>
        <td class="aatd"><img src='./CartPole-v0/images/figs_0911_CartPole_global_median_GaussAug/CartPole_global_median_sigma-0.005_cmp.pdf'></td>
        
        <td class="datatd"><img src='./CartPole-v0/images/figs_0911_CartPole_global_median_GaussAug/CartPole_global_median_sigma-0.01_cmp.pdf'></td>
        <td class="archtd"><img src='./CartPole-v0/images/figs_0911_CartPole_global_median_GaussAug/CartPole_global_median_sigma-0.03_cmp.pdf'></td>
        <td class="venuetd"><img src='./CartPole-v0/images/figs_0911_CartPole_global_median_GaussAug/CartPole_global_median_sigma-0.05_cmp.pdf'></td>
        <td class="venuetd_2"><img src='./CartPole-v0/images/figs_0911_CartPole_global_median_GaussAug/CartPole_global_median_sigma-0.1_cmp.pdf'></td>
    </tr>

    <tr>
        <td class="ranktd">5</td>
        <td class="methoddt">
            <a href="https://arxiv.org/abs/2003.08938" target="_blank">Robust Deep Reinforcement Learning against Adversarial Perturbations on State Observations</a>
            
            <br>
            <span class="td-footer">
                Trained with PGD regularization.
            </span>
            
        </td>
        <td class="catd"><img src='./CartPole-v0/images/figs_0911_CartPole_global_median_RegPGD/CartPole_global_median_sigma-0.001_cmp.pdf'></td>
        <td class="aatd"><img src='./CartPole-v0/images/figs_0911_CartPole_global_median_RegPGD/CartPole_global_median_sigma-0.005_cmp.pdf'></td>
        
        <td class="datatd"><img src='./CartPole-v0/images/figs_0911_CartPole_global_median_RegPGD/CartPole_global_median_sigma-0.01_cmp.pdf'></td>
        <td class="archtd"><img src='./CartPole-v0/images/figs_0911_CartPole_global_median_RegPGD/CartPole_global_median_sigma-0.03_cmp.pdf'></td>
        <td class="venuetd"><img src='./CartPole-v0/images/figs_0911_CartPole_global_median_RegPGD/CartPole_global_median_sigma-0.05_cmp.pdf'></td>
        <td class="venuetd_2"><img src='./CartPole-v0/images/figs_0911_CartPole_global_median_RegPGD/CartPole_global_median_sigma-0.1_cmp.pdf'></td>
    </tr>
    
    <tr>
        <td class="ranktd">6</td>
        <td class="methoddt">
            <a href="https://arxiv.org/abs/2003.08938" target="_blank">Robust Deep Reinforcement Learning against Adversarial Perturbations on State Observations</a>
            
            <br>
            <span class="td-footer">
                Training with convex regularization.
            </span>
            
        </td>
        <td class="catd"><img src='./CartPole-v0/images/figs_0911_CartPole_global_median_RegCVX/CartPole_global_median_sigma-0.001_cmp.pdf'></td>
        <td class="aatd"><img src='./CartPole-v0/images/figs_0911_CartPole_global_median_RegCVX/CartPole_global_median_sigma-0.005_cmp.pdf'></td>
        
        <td class="datatd"><img src='./CartPole-v0/images/figs_0911_CartPole_global_median_RegCVX/CartPole_global_median_sigma-0.01_cmp.pdf'></td>
        <td class="archtd"><img src='./CartPole-v0/images/figs_0911_CartPole_global_median_RegCVX/CartPole_global_median_sigma-0.03_cmp.pdf'></td>
        <td class="venuetd"><img src='./CartPole-v0/images/figs_0911_CartPole_global_median_RegCVX/CartPole_global_median_sigma-0.05_cmp.pdf'></td>
        <td class="venuetd_2"><img src='./CartPole-v0/images/figs_0911_CartPole_global_median_RegCVX/CartPole_global_median_sigma-0.1_cmp.pdf'></td>
    </tr>
    
    <tr>
        <td class="ranktd">7</td>
        <td class="methoddt">
            <a href="https://arxiv.org/abs/1706.10295" target="_blank">Noisy Networks for Exploration</a>
            
        </td>
        <td class="catd"><img src='./CartPole-v0/images/figs_0911_CartPole_global_median_NoisyNet/CartPole_global_median_sigma-0.001_cmp.pdf'></td>
        <td class="aatd"><img src='./CartPole-v0/images/figs_0911_CartPole_global_median_NoisyNet/CartPole_global_median_sigma-0.005_cmp.pdf'></td>
        
        <td class="datatd"><img src='./CartPole-v0/images/figs_0911_CartPole_global_median_NoisyNet/CartPole_global_median_sigma-0.01_cmp.pdf'></td>
        <td class="archtd"><img src='./CartPole-v0/images/figs_0911_CartPole_global_median_NoisyNet/CartPole_global_median_sigma-0.03_cmp.pdf'></td>
        <td class="venuetd"><img src='./CartPole-v0/images/figs_0911_CartPole_global_median_NoisyNet/CartPole_global_median_sigma-0.05_cmp.pdf'></td>
        <td class="venuetd_2"><img src='./CartPole-v0/images/figs_0911_CartPole_global_median_NoisyNet/CartPole_global_median_sigma-0.1_cmp.pdf'></td>
    </tr>
    </tr>
    
    <tr>
        <td class="ranktd">8</td>
        <td class="methoddt">
            <a href="https://arxiv.org/abs/1712.03632" target="_blank">Robust Deep Reinforcement Learning with Adversarial Attacks</a>
            
        </td>
        <td class="catd"><img src='./CartPole-v0/images/figs_0911_CartPole_global_median_GradDQN/CartPole_global_median_sigma-0.001_cmp.pdf'></td>
        <td class="aatd"><img src='./CartPole-v0/images/figs_0911_CartPole_global_median_GradDQN/CartPole_global_median_sigma-0.005_cmp.pdf'></td>
        
        <td class="datatd"><img src='./CartPole-v0/images/figs_0911_CartPole_global_median_GradDQN/CartPole_global_median_sigma-0.01_cmp.pdf'></td>
        <td class="archtd"><img src='./CartPole-v0/images/figs_0911_CartPole_global_median_GradDQN/CartPole_global_median_sigma-0.03_cmp.pdf'></td>
        <td class="venuetd"><img src='./CartPole-v0/images/figs_0911_CartPole_global_median_GradDQN/CartPole_global_median_sigma-0.05_cmp.pdf'></td>
        <td class="venuetd_2"><img src='./CartPole-v0/images/figs_0911_CartPole_global_median_GradDQN/CartPole_global_median_sigma-0.1_cmp.pdf'></td>
    </tr>
    
    <tr>
        <td class="ranktd">9</td>
        <td class="methoddt">
            <a href="https://arxiv.org/abs/1712.09344" target="_blank">Whatever Does Not Kill Deep Reinforcement Learning, Makes It Stronger</a>

            <br>
            <span class="td-footer">
                Trained with adversarial states.
            </span>
            
        </td>
        <td class="catd"><img src='./CartPole-v0/images/figs_0911_CartPole_global_median_AdvTrain/CartPole_global_median_sigma-0.001_cmp.pdf'></td>
        <td class="aatd"><img src='./CartPole-v0/images/figs_0911_CartPole_global_median_AdvTrain/CartPole_global_median_sigma-0.005_cmp.pdf'></td>
        
        <td class="datatd"><img src='./CartPole-v0/images/figs_0911_CartPole_global_median_AdvTrain/CartPole_global_median_sigma-0.01_cmp.pdf'></td>
        <td class="archtd"><img src='./CartPole-v0/images/figs_0911_CartPole_global_median_AdvTrain/CartPole_global_median_sigma-0.03_cmp.pdf'></td>
        <td class="venuetd"><img src='./CartPole-v0/images/figs_0911_CartPole_global_median_AdvTrain/CartPole_global_median_sigma-0.05_cmp.pdf'></td>
        <td class="venuetd_2"><img src='./CartPole-v0/images/figs_0911_CartPole_global_median_AdvTrain/CartPole_global_median_sigma-0.1_cmp.pdf'></td>
    </tr>

    <tr>
        <td class="ranktd">All</td>
        <td class="methoddt">
            Comparison between all different methods
            
        </td>
        <td class="catd"><img src='./CartPole-v0/images/figs_0917_CartPole_global/CartPole_global_median_sigma-0.001_cmp.pdf'></td>
        <td class="aatd"><img src='./CartPole-v0/images/figs_0917_CartPole_global/CartPole_global_median_sigma-0.005_cmp.pdf'></td>
        
        <td class="datatd"><img src='./CartPole-v0/images/figs_0917_CartPole_global/CartPole_global_median_sigma-0.01_cmp.pdf'></td>
        <td class="archtd"><img src='./CartPole-v0/images/figs_0917_CartPole_global/CartPole_global_median_sigma-0.03_cmp.pdf'></td>
        <td class="venuetd"><img src='./CartPole-v0/images/figs_0917_CartPole_global/CartPole_global_median_sigma-0.05_cmp.pdf'></td>
        <td class="venuetd_2"><img src='./CartPole-v0/images/figs_0917_CartPole_global/CartPole_global_median_sigma-0.1_cmp.pdf'></td>
    </tr>
    
    </tbody>
</table>
<script>
    $(document).ready(function () {
        $("#CartPole-v0_leaderboard_GRe-median").DataTable({
            lengthMenu: [15, 25, 50, 75, 100],
            "drawCallback": function (settings) {
                MathJax.Hub.Queue(["Typeset", MathJax.Hub]);
            },
            language: {
                searchPlaceholder: "Papers, architectures, venues"
            },
            
        });
    });
</script>
