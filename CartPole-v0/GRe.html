<table id="artPole-v0_leaderboard_GRe" class="datatable" style="width: 100%">
    <thead>
    <tr>
        <th class="rank">Rank</th>
        <th class="method">Method</th>
        <th class="ca">
            Standard<br/>
            accuracy
        </th>
        
        <th class="aa">
            AutoAttack<br/>
            robust<br/>
            accuracy
        </th>
        <th class="aa-ext">
            Best known<br/>
            robust<br/>
            accuracy
        </th>
        <th class="aa-ext">
            AA eval.<br/>
            potentially<br/>
            unreliable
        </th>
        
        
        <th class="extra-data">Extra <br/>data</th>
        <th class="arch">Architecture</th>
        <th class="venue">Venue</th>
    </tr>
    </thead>
    <tbody>
    
    <tr>
        <td class="ranktd">1</td>
        <td class="methoddt">
            <a href="https://arxiv.org/abs/2103.01946" target="_blank">Fixing Data Augmentation to Improve Adversarial Robustness</a>
            
            <br>
            <span class="td-footer">
                66.56% robust accuracy is due to the original evaluation (AutoAttack + MultiTargeted)
            </span>
            
        </td>
        <td class="catd">92.23%</td>
        <td class="aatd">66.58%</td>
        
        <td class="aa-extd">66.56%</td>
        <td class="flagsd"><div class="flagsd-emoji">&#215;</div></td>
        
        <td class="datatd">&#9745;</td>
        <td class="archtd">WideResNet-70-16</td>
        <td class="venuetd">arXiv, Mar 2021</td>
    </tr>
    
    <tr>
        <td class="ranktd">2</td>
        <td class="methoddt">
            <a href="https://arxiv.org/abs/2010.03593" target="_blank">Uncovering the Limits of Adversarial Training against Norm-Bounded Adversarial Examples</a>
            
            <br>
            <span class="td-footer">
                65.87% robust accuracy is due to the original evaluation (AutoAttack + MultiTargeted)
            </span>
            
        </td>
        <td class="catd">91.10%</td>
        <td class="aatd">65.88%</td>
        
        <td class="aa-extd">65.87%</td>
        <td class="flagsd"><div class="flagsd-emoji">&#215;</div></td>
        
        <td class="datatd">&#9745;</td>
        <td class="archtd">WideResNet-70-16</td>
        <td class="venuetd">arXiv, Oct 2020</td>
    </tr>
    
    <tr>
        <td class="ranktd">3</td>
        <td class="methoddt">
            <a href="https://arxiv.org/abs/2103.01946" target="_blank">Fixing Data Augmentation to Improve Adversarial Robustness</a>
            
            <br>
            <span class="td-footer">
                It uses additional 1M synthetic images in training. 64.58% robust accuracy is due to the original evaluation (AutoAttack + MultiTargeted)
            </span>
            
        </td>
        <td class="catd">88.50%</td>
        <td class="aatd">64.64%</td>
        
        <td class="aa-extd">64.58%</td>
        <td class="flagsd"><div class="flagsd-emoji">&#215;</div></td>
        
        <td class="datatd">&#215;</td>
        <td class="archtd">WideResNet-106-16</td>
        <td class="venuetd">arXiv, Mar 2021</td>
    </tr>
    
    <tr>
        <td class="ranktd">4</td>
        <td class="methoddt">
            <a href="https://arxiv.org/abs/2103.01946" target="_blank">Fixing Data Augmentation to Improve Adversarial Robustness</a>
            
            <br>
            <span class="td-footer">
                It uses additional 1M synthetic images in training. 64.20% robust accuracy is due to the original evaluation (AutoAttack + MultiTargeted)
            </span>
            
        </td>
        <td class="catd">88.54%</td>
        <td class="aatd">64.25%</td>
        
        <td class="aa-extd">64.20%</td>
        <td class="flagsd"><div class="flagsd-emoji">&#215;</div></td>
        
        <td class="datatd">&#215;</td>
        <td class="archtd">WideResNet-70-16</td>
        <td class="venuetd">arXiv, Mar 2021</td>
    </tr>
    
    <tr>
        <td class="ranktd">5</td>
        <td class="methoddt">
            <a href="https://openreview.net/forum?id=BuD2LmNaU3a" target="_blank">Helper-based Adversarial Training: Reducing Excessive Margin to Achieve a Better Accuracy vs. Robustness Trade-off</a>
            
        </td>
        <td class="catd">91.47%</td>
        <td class="aatd">62.83%</td>
        
        <td class="aa-extd">62.83%</td>
        <td class="flagsd"><div class="flagsd-emoji">&#215;</div></td>
        
        <td class="datatd">&#9745;</td>
        <td class="archtd">WideResNet-34-10</td>
        <td class="venuetd">OpenReview, Jun 2021</td>
    </tr>
    
    <tr>
        <td class="ranktd">6</td>
        <td class="methoddt">
            <a href="https://arxiv.org/abs/2010.03593" target="_blank">Uncovering the Limits of Adversarial Training against Norm-Bounded Adversarial Examples</a>
            
            <br>
            <span class="td-footer">
                62.76% robust accuracy is due to the original evaluation (AutoAttack + MultiTargeted)
            </span>
            
        </td>
        <td class="catd">89.48%</td>
        <td class="aatd">62.80%</td>
        
        <td class="aa-extd">62.76%</td>
        <td class="flagsd"><div class="flagsd-emoji">&#215;</div></td>
        
        <td class="datatd">&#9745;</td>
        <td class="archtd">WideResNet-28-10</td>
        <td class="venuetd">arXiv, Oct 2020</td>
    </tr>
    
    <tr>
        <td class="ranktd">7</td>
        <td class="methoddt">
            <a href="https://openreview.net/forum?id=BuD2LmNaU3a" target="_blank">Helper-based Adversarial Training: Reducing Excessive Margin to Achieve a Better Accuracy vs. Robustness Trade-off</a>
            
            <br>
            <span class="td-footer">
                It uses additional 1M synthetic images in training.
            </span>
            
        </td>
        <td class="catd">88.16%</td>
        <td class="aatd">60.97%</td>
        
        <td class="aa-extd">60.97%</td>
        <td class="flagsd"><div class="flagsd-emoji">&#215;</div></td>
        
        <td class="datatd">&#215;</td>
        <td class="archtd">WideResNet-28-10</td>
        <td class="venuetd">OpenReview, Jun 2021</td>
    </tr>
    
    <tr>
        <td class="ranktd">8</td>
        <td class="methoddt">
            <a href="https://arxiv.org/abs/2103.01946" target="_blank">Fixing Data Augmentation to Improve Adversarial Robustness</a>
            
            <br>
            <span class="td-footer">
                It uses additional 1M synthetic images in training. 60.73% robust accuracy is due to the original evaluation (AutoAttack + MultiTargeted)
            </span>
            
        </td>
        <td class="catd">87.33%</td>
        <td class="aatd">60.75%</td>
        
        <td class="aa-extd">60.73%</td>
        <td class="flagsd"><div class="flagsd-emoji">&#215;</div></td>
        
        <td class="datatd">&#215;</td>
        <td class="archtd">WideResNet-28-10</td>
        <td class="venuetd">arXiv, Mar 2021</td>
    </tr>
    
    <tr>
        <td class="ranktd">9</td>
        <td class="methoddt">
            <a href="https://arxiv.org/abs/2010.01279" target="_blank">Do Wider Neural Networks Really Help Adversarial Robustness?</a>
            
            <br>
            <span class="td-footer">
                
            </span>
            
        </td>
        <td class="catd">87.67%</td>
        <td class="aatd">60.65%</td>
        
        <td class="aa-extd">60.65%</td>
        <td class="flagsd">Unknown</td>
        
        <td class="datatd">&#9745;</td>
        <td class="archtd">WideResNet-34-15</td>
        <td class="venuetd">arXiv, Oct 2020</td>
    </tr>
    
    <tr>
        <td class="ranktd">10</td>
        <td class="methoddt">
            <a href="https://arxiv.org/abs/2106.02078" target="_blank">Robust Learning via Persistency of Excitation</a>
            
        </td>
        <td class="catd">86.53%</td>
        <td class="aatd">60.41%</td>
        
        <td class="aa-extd">60.41%</td>
        <td class="flagsd"><div class="flagsd-emoji">&#215;</div></td>
        
        <td class="datatd">&#9745;</td>
        <td class="archtd">WideResNet-34-15</td>
        <td class="venuetd">arXiv, Jun 2021</td>
    </tr>
    
    <tr>
        <td class="ranktd">11</td>
        <td class="methoddt">
            <a href="https://arxiv.org/abs/2004.05884" target="_blank">Adversarial Weight Perturbation Helps Robust Generalization</a>
            
        </td>
        <td class="catd">88.25%</td>
        <td class="aatd">60.04%</td>
        
        <td class="aa-extd">60.04%</td>
        <td class="flagsd"><div class="flagsd-emoji">&#215;</div></td>
        
        <td class="datatd">&#9745;</td>
        <td class="archtd">WideResNet-28-10</td>
        <td class="venuetd">NeurIPS 2020</td>
    </tr>
    
    <tr>
        <td class="ranktd">12</td>
        <td class="methoddt">
            <a href="https://arxiv.org/abs/2106.02078" target="_blank">Robust Learning via Persistency of Excitation</a>
            
        </td>
        <td class="catd">89.46%</td>
        <td class="aatd">59.66%</td>
        
        <td class="aa-extd">59.66%</td>
        <td class="flagsd"><div class="flagsd-emoji">&#215;</div></td>
        
        <td class="datatd">&#9745;</td>
        <td class="archtd">WideResNet-28-10</td>
        <td class="venuetd">arXiv, Jun 2021</td>
    </tr>
    
    <tr>
        <td class="ranktd">13</td>
        <td class="methoddt">
            <a href="https://arxiv.org/abs/2010.01736" target="_blank">Geometry-aware Instance-reweighted Adversarial Training</a>
            
            <br>
            <span class="td-footer">
                Uses \(\ell_{\infty} \) = 0.031 â‰ˆ 7.9/255 instead of 8/255.
            </span>
            
        </td>
        <td class="catd">89.36%</td>
        <td class="aatd">59.64%</td>
        
        <td class="aa-extd">59.64%</td>
        <td class="flagsd"><div class="flagsd-emoji">&#215;</div></td>
        
        <td class="datatd">&#9745;</td>
        <td class="archtd">WideResNet-28-10</td>
        <td class="venuetd">ICLR 2021</td>
    </tr>
    
    <tr>
        <td class="ranktd">14</td>
        <td class="methoddt">
            <a href="https://arxiv.org/abs/1905.13736" target="_blank">Unlabeled Data Improves Adversarial Robustness</a>
            
        </td>
        <td class="catd">89.69%</td>
        <td class="aatd">59.53%</td>
        
        <td class="aa-extd">59.53%</td>
        <td class="flagsd">Unknown</td>
        
        <td class="datatd">&#9745;</td>
        <td class="archtd">WideResNet-28-10</td>
        <td class="venuetd">NeurIPS 2019</td>
    </tr>
    
    <tr>
        <td class="ranktd">15</td>
        <td class="methoddt">
            <a href="https://arxiv.org/abs/2104.09425" target="_blank">Improving Adversarial Robustness Using Proxy Distributions</a>
            
            <br>
            <span class="td-footer">
                It uses additional ~6M synthetic images in training.
            </span>
            
        </td>
        <td class="catd">85.85%</td>
        <td class="aatd">59.09%</td>
        
        <td class="aa-extd">59.09%</td>
        <td class="flagsd">Unknown</td>
        
        <td class="datatd">&#215;</td>
        <td class="archtd">WideResNet-34-10</td>
        <td class="venuetd">arXiv, Apr 2021</td>
    </tr>
    
    <tr>
        <td class="ranktd">16</td>
        <td class="methoddt">
            <a href="https://openreview.net/forum?id=BuD2LmNaU3a" target="_blank">Helper-based Adversarial Training: Reducing Excessive Margin to Achieve a Better Accuracy vs. Robustness Trade-off</a>
            
        </td>
        <td class="catd">89.02%</td>
        <td class="aatd">57.67%</td>
        
        <td class="aa-extd">57.67%</td>
        <td class="flagsd"><div class="flagsd-emoji">&#215;</div></td>
        
        <td class="datatd">&#9745;</td>
        <td class="archtd">PreActResNet-18</td>
        <td class="venuetd">OpenReview, Jun 2021</td>
    </tr>
    
    <tr>
        <td class="ranktd">17</td>
        <td class="methoddt">
            <a href="https://arxiv.org/abs/2010.03593" target="_blank">Uncovering the Limits of Adversarial Training against Norm-Bounded Adversarial Examples</a>
            
            <br>
            <span class="td-footer">
                57.14% robust accuracy is due to the original evaluation (AutoAttack + MultiTargeted)
            </span>
            
        </td>
        <td class="catd">85.29%</td>
        <td class="aatd">57.20%</td>
        
        <td class="aa-extd">57.14%</td>
        <td class="flagsd"><div class="flagsd-emoji">&#215;</div></td>
        
        <td class="datatd">&#215;</td>
        <td class="archtd">WideResNet-70-16</td>
        <td class="venuetd">arXiv, Oct 2020</td>
    </tr>
    
    <tr>
        <td class="ranktd">18</td>
        <td class="methoddt">
            <a href="https://arxiv.org/abs/2002.10509" target="_blank">HYDRA: Pruning Adversarially Robust Neural Networks</a>
            
            <br>
            <span class="td-footer">
                Compressed model
            </span>
            
        </td>
        <td class="catd">88.98%</td>
        <td class="aatd">57.14%</td>
        
        <td class="aa-extd">57.14%</td>
        <td class="flagsd">Unknown</td>
        
        <td class="datatd">&#9745;</td>
        <td class="archtd">WideResNet-28-10</td>
        <td class="venuetd">NeurIPS 2020</td>
    </tr>
    
    <tr>
        <td class="ranktd">19</td>
        <td class="methoddt">
            <a href="https://openreview.net/forum?id=BuD2LmNaU3a" target="_blank">Helper-based Adversarial Training: Reducing Excessive Margin to Achieve a Better Accuracy vs. Robustness Trade-off</a>
            
            <br>
            <span class="td-footer">
                It uses additional 1M synthetic images in training.
            </span>
            
        </td>
        <td class="catd">86.86%</td>
        <td class="aatd">57.09%</td>
        
        <td class="aa-extd">57.09%</td>
        <td class="flagsd"><div class="flagsd-emoji">&#215;</div></td>
        
        <td class="datatd">&#215;</td>
        <td class="archtd">PreActResNet-18</td>
        <td class="venuetd">OpenReview, Jun 2021</td>
    </tr>
    
    <tr>
        <td class="ranktd">20</td>
        <td class="methoddt">
            <a href="https://arxiv.org/abs/2010.03593" target="_blank">Uncovering the Limits of Adversarial Training against Norm-Bounded Adversarial Examples</a>
            
            <br>
            <span class="td-footer">
                56.82% robust accuracy is due to the original evaluation (AutoAttack + MultiTargeted)
            </span>
            
        </td>
        <td class="catd">85.64%</td>
        <td class="aatd">56.86%</td>
        
        <td class="aa-extd">56.82%</td>
        <td class="flagsd"><div class="flagsd-emoji">&#215;</div></td>
        
        <td class="datatd">&#215;</td>
        <td class="archtd">WideResNet-34-20</td>
        <td class="venuetd">arXiv, Oct 2020</td>
    </tr>
    
    <tr>
        <td class="ranktd">21</td>
        <td class="methoddt">
            <a href="https://arxiv.org/abs/2103.01946" target="_blank">Fixing Data Augmentation to Improve Adversarial Robustness</a>
            
            <br>
            <span class="td-footer">
                It uses additional 1M synthetic images in training.
            </span>
            
        </td>
        <td class="catd">83.53%</td>
        <td class="aatd">56.66%</td>
        
        <td class="aa-extd">56.66%</td>
        <td class="flagsd"><div class="flagsd-emoji">&#215;</div></td>
        
        <td class="datatd">&#215;</td>
        <td class="archtd">PreActResNet-18</td>
        <td class="venuetd">arXiv, Mar 2021</td>
    </tr>
    
    <tr>
        <td class="ranktd">22</td>
        <td class="methoddt">
            <a href="https://openreview.net/forum?id=rklOg6EFwS" target="_blank">Improving Adversarial Robustness Requires Revisiting Misclassified Examples</a>
            
        </td>
        <td class="catd">87.50%</td>
        <td class="aatd">56.29%</td>
        
        <td class="aa-extd">56.29%</td>
        <td class="flagsd">Unknown</td>
        
        <td class="datatd">&#9745;</td>
        <td class="archtd">WideResNet-28-10</td>
        <td class="venuetd">ICLR 2020</td>
    </tr>
    
    <tr>
        <td class="ranktd">23</td>
        <td class="methoddt">
            <a href="https://arxiv.org/abs/2004.05884" target="_blank">Adversarial Weight Perturbation Helps Robust Generalization</a>
            
        </td>
        <td class="catd">85.36%</td>
        <td class="aatd">56.17%</td>
        
        <td class="aa-extd">56.17%</td>
        <td class="flagsd"><div class="flagsd-emoji">&#215;</div></td>
        
        <td class="datatd">&#215;</td>
        <td class="archtd">WideResNet-34-10</td>
        <td class="venuetd">NeurIPS 2020</td>
    </tr>
    
    <tr>
        <td class="ranktd">24</td>
        <td class="methoddt">
            <a href="https://arxiv.org/abs/1905.13725" target="_blank">Are Labels Required for Improving Adversarial Robustness?</a>
            
        </td>
        <td class="catd">86.46%</td>
        <td class="aatd">56.03%</td>
        
        <td class="aa-extd">56.03%</td>
        <td class="flagsd">Unknown</td>
        
        <td class="datatd">&#9745;</td>
        <td class="archtd">WideResNet-28-10</td>
        <td class="venuetd">NeurIPS 2019</td>
    </tr>
    
    <tr>
        <td class="ranktd">25</td>
        <td class="methoddt">
            <a href="https://arxiv.org/abs/1901.09960" target="_blank">Using Pre-Training Can Improve Model Robustness and Uncertainty</a>
            
        </td>
        <td class="catd">87.11%</td>
        <td class="aatd">54.92%</td>
        
        <td class="aa-extd">54.92%</td>
        <td class="flagsd">Unknown</td>
        
        <td class="datatd">&#9745;</td>
        <td class="archtd">WideResNet-28-10</td>
        <td class="venuetd">ICML 2019</td>
    </tr>
    
    <tr>
        <td class="ranktd">26</td>
        <td class="methoddt">
            <a href="https://arxiv.org/abs/2104.09425" target="_blank">Improving Adversarial Robustness Using Proxy Distributions</a>
            
            <br>
            <span class="td-footer">
                It uses additional ~6M synthetic images in training.
            </span>
            
        </td>
        <td class="catd">84.38%</td>
        <td class="aatd">54.43%</td>
        
        <td class="aa-extd">54.43%</td>
        <td class="flagsd">Unknown</td>
        
        <td class="datatd">&#215;</td>
        <td class="archtd">ResNet-18</td>
        <td class="venuetd">arXiv, Apr 2021</td>
    </tr>
    
    <tr>
        <td class="ranktd">27</td>
        <td class="methoddt">
            <a href="https://arxiv.org/abs/2010.00467" target="_blank">Bag of Tricks for Adversarial Training</a>
            
            <br>
            <span class="td-footer">
                
            </span>
            
        </td>
        <td class="catd">86.43%</td>
        <td class="aatd">54.39%</td>
        
        <td class="aa-extd">54.39%</td>
        <td class="flagsd">Unknown</td>
        
        <td class="datatd">&#215;</td>
        <td class="archtd">WideResNet-34-20</td>
        <td class="venuetd">ICLR 2021</td>
    </tr>
    
    <tr>
        <td class="ranktd">28</td>
        <td class="methoddt">
            <a href="https://arxiv.org/abs/2002.08619" target="_blank">Boosting Adversarial Training with Hypersphere Embedding</a>
            
        </td>
        <td class="catd">85.14%</td>
        <td class="aatd">53.74%</td>
        
        <td class="aa-extd">53.74%</td>
        <td class="flagsd">Unknown</td>
        
        <td class="datatd">&#215;</td>
        <td class="archtd">WideResNet-34-20</td>
        <td class="venuetd">NeurIPS 2020</td>
    </tr>
    
    <tr>
        <td class="ranktd">29</td>
        <td class="methoddt">
            <a href="https://arxiv.org/abs/2011.11164" target="_blank">Learnable Boundary Guided Adversarial Training</a>
            
            <br>
            <span class="td-footer">
                Uses \(\ell_{\infty} \) = 0.031 â‰ˆ 7.9/255 instead of 8/255
            </span>
            
        </td>
        <td class="catd">88.70%</td>
        <td class="aatd">53.57%</td>
        
        <td class="aa-extd">53.57%</td>
        <td class="flagsd"><div class="flagsd-emoji">&#215;</div></td>
        
        <td class="datatd">&#215;</td>
        <td class="archtd">WideResNet-34-20</td>
        <td class="venuetd">ICCV 2021</td>
    </tr>
    
    <tr>
        <td class="ranktd">30</td>
        <td class="methoddt">
            <a href="https://arxiv.org/abs/2002.11242" target="_blank">Attacks Which Do Not Kill Training Make Adversarial Learning Stronger</a>
            
        </td>
        <td class="catd">84.52%</td>
        <td class="aatd">53.51%</td>
        
        <td class="aa-extd">53.51%</td>
        <td class="flagsd">Unknown</td>
        
        <td class="datatd">&#215;</td>
        <td class="archtd">WideResNet-34-10</td>
        <td class="venuetd">ICML 2020</td>
    </tr>
    
    <tr>
        <td class="ranktd">31</td>
        <td class="methoddt">
            <a href="https://arxiv.org/abs/2002.11569" target="_blank">Overfitting in adversarially robust deep learning</a>
            
        </td>
        <td class="catd">85.34%</td>
        <td class="aatd">53.42%</td>
        
        <td class="aa-extd">53.42%</td>
        <td class="flagsd">Unknown</td>
        
        <td class="datatd">&#215;</td>
        <td class="archtd">WideResNet-34-20</td>
        <td class="venuetd">ICML 2020</td>
    </tr>
    
    <tr>
        <td class="ranktd">32</td>
        <td class="methoddt">
            <a href="https://arxiv.org/abs/2002.10319" target="_blank">Self-Adaptive Training: beyond Empirical Risk Minimization</a>
            
            <br>
            <span class="td-footer">
                Uses \(\ell_{\infty} \) = 0.031 â‰ˆ 7.9/255 instead of 8/255.
            </span>
            
        </td>
        <td class="catd">83.48%</td>
        <td class="aatd">53.34%</td>
        
        <td class="aa-extd">53.34%</td>
        <td class="flagsd">Unknown</td>
        
        <td class="datatd">&#215;</td>
        <td class="archtd">WideResNet-34-10</td>
        <td class="venuetd">NeurIPS 2020</td>
    </tr>
    
    <tr>
        <td class="ranktd">33</td>
        <td class="methoddt">
            <a href="https://arxiv.org/abs/1901.08573" target="_blank">Theoretically Principled Trade-off between Robustness and Accuracy</a>
            
            <br>
            <span class="td-footer">
                Uses \(\ell_{\infty} \) = 0.031 â‰ˆ 7.9/255 instead of 8/255.
            </span>
            
        </td>
        <td class="catd">84.92%</td>
        <td class="aatd">53.08%</td>
        
        <td class="aa-extd">53.08%</td>
        <td class="flagsd">Unknown</td>
        
        <td class="datatd">&#215;</td>
        <td class="archtd">WideResNet-34-10</td>
        <td class="venuetd">ICML 2019</td>
    </tr>
    
    <tr>
        <td class="ranktd">34</td>
        <td class="methoddt">
            <a href="https://arxiv.org/abs/2011.11164" target="_blank">Learnable Boundary Guided Adversarial Training</a>
            
            <br>
            <span class="td-footer">
                Uses \(\ell_{\infty} \) = 0.031 â‰ˆ 7.9/255 instead of 8/255
            </span>
            
        </td>
        <td class="catd">88.22%</td>
        <td class="aatd">52.86%</td>
        
        <td class="aa-extd">52.86%</td>
        <td class="flagsd"><div class="flagsd-emoji">&#215;</div></td>
        
        <td class="datatd">&#215;</td>
        <td class="archtd">WideResNet-34-10</td>
        <td class="venuetd">ICCV 2021</td>
    </tr>
    
    <tr>
        <td class="ranktd">35</td>
        <td class="methoddt">
            <a href="https://arxiv.org/abs/1907.02610v2" target="_blank">Adversarial Robustness through Local Linearization</a>
            
        </td>
        <td class="catd">86.28%</td>
        <td class="aatd">52.84%</td>
        
        <td class="aa-extd">52.84%</td>
        <td class="flagsd">Unknown</td>
        
        <td class="datatd">&#215;</td>
        <td class="archtd">WideResNet-40-8</td>
        <td class="venuetd">NeurIPS 2019</td>
    </tr>
    
    <tr>
        <td class="ranktd">36</td>
        <td class="methoddt">
            <a href="https://arxiv.org/abs/2003.12862" target="_blank">Adversarial Robustness: From Self-Supervised Pre-Training to Fine-Tuning</a>
            
            <br>
            <span class="td-footer">
                Uses ensembles of 3 models.
            </span>
            
        </td>
        <td class="catd">86.04%</td>
        <td class="aatd">51.56%</td>
        
        <td class="aa-extd">51.56%</td>
        <td class="flagsd">Unknown</td>
        
        <td class="datatd">&#215;</td>
        <td class="archtd">ResNet-50</td>
        <td class="venuetd">CVPR 2020</td>
    </tr>
    
    <tr>
        <td class="ranktd">37</td>
        <td class="methoddt">
            <a href="https://arxiv.org/abs/2010.01278" target="_blank">Efficient Robust Training via Backward Smoothing</a>
            
            <br>
            <span class="td-footer">
                
            </span>
            
        </td>
        <td class="catd">85.32%</td>
        <td class="aatd">51.12%</td>
        
        <td class="aa-extd">51.12%</td>
        <td class="flagsd">Unknown</td>
        
        <td class="datatd">&#215;</td>
        <td class="archtd">WideResNet-34-10</td>
        <td class="venuetd">arXiv, Oct 2020</td>
    </tr>
    
    <tr>
        <td class="ranktd">38</td>
        <td class="methoddt">
            <a href="https://arxiv.org/abs/2003.09347" target="_blank">Improving Adversarial Robustness Through Progressive Hardening</a>
            
            <br>
            <span class="td-footer">
                
            </span>
            
        </td>
        <td class="catd">86.84%</td>
        <td class="aatd">50.72%</td>
        
        <td class="aa-extd">50.72%</td>
        <td class="flagsd">Unknown</td>
        
        <td class="datatd">&#215;</td>
        <td class="archtd">WideResNet-34-10</td>
        <td class="venuetd">arXiv, Mar 2020</td>
    </tr>
    
    <tr>
        <td class="ranktd">39</td>
        <td class="methoddt">
            <a href="https://github.com/MadryLab/robustness" target="_blank">Robustness library</a>
            
        </td>
        <td class="catd">87.03%</td>
        <td class="aatd">49.25%</td>
        
        <td class="aa-extd">49.25%</td>
        <td class="flagsd">Unknown</td>
        
        <td class="datatd">&#215;</td>
        <td class="archtd">ResNet-50</td>
        <td class="venuetd">GitHub,<br>Oct 2019</td>
    </tr>
    
    <tr>
        <td class="ranktd">40</td>
        <td class="methoddt">
            <a href="https://arxiv.org/abs/1905.05186" target="_blank">Harnessing the Vulnerability of Latent Layers in Adversarially Trained Models</a>
            
        </td>
        <td class="catd">87.80%</td>
        <td class="aatd">49.12%</td>
        
        <td class="aa-extd">49.12%</td>
        <td class="flagsd">Unknown</td>
        
        <td class="datatd">&#215;</td>
        <td class="archtd">WideResNet-34-10</td>
        <td class="venuetd">IJCAI 2019</td>
    </tr>
    
    <tr>
        <td class="ranktd">41</td>
        <td class="methoddt">
            <a href="http://papers.nips.cc/paper/8339-metric-learning-for-adversarial-robustness" target="_blank">Metric Learning for Adversarial Robustness</a>
            
        </td>
        <td class="catd">86.21%</td>
        <td class="aatd">47.41%</td>
        
        <td class="aa-extd">47.41%</td>
        <td class="flagsd">Unknown</td>
        
        <td class="datatd">&#215;</td>
        <td class="archtd">WideResNet-34-10</td>
        <td class="venuetd">NeurIPS 2019</td>
    </tr>
    
    <tr>
        <td class="ranktd">42</td>
        <td class="methoddt">
            <a href="https://arxiv.org/abs/1905.00877" target="_blank">You Only Propagate Once: Accelerating Adversarial Training via Maximal Principle</a>
            
            <br>
            <span class="td-footer">
                Focuses on fast adversarial training.
            </span>
            
        </td>
        <td class="catd">87.20%</td>
        <td class="aatd">44.83%</td>
        
        <td class="aa-extd">44.83%</td>
        <td class="flagsd">Unknown</td>
        
        <td class="datatd">&#215;</td>
        <td class="archtd">WideResNet-34-10</td>
        <td class="venuetd">NeurIPS 2019</td>
    </tr>
    
    <tr>
        <td class="ranktd">43</td>
        <td class="methoddt">
            <a href="https://arxiv.org/abs/1706.06083" target="_blank">Towards Deep Learning Models Resistant to Adversarial Attacks</a>
            
        </td>
        <td class="catd">87.14%</td>
        <td class="aatd">44.04%</td>
        
        <td class="aa-extd">44.04%</td>
        <td class="flagsd">Unknown</td>
        
        <td class="datatd">&#215;</td>
        <td class="archtd">WideResNet-34-10</td>
        <td class="venuetd">ICLR 2018</td>
    </tr>
    
    <tr>
        <td class="ranktd">44</td>
        <td class="methoddt">
            <a href="https://arxiv.org/abs/2007.02617" target="_blank">Understanding and Improving Fast Adversarial Training</a>
            
            <br>
            <span class="td-footer">
                Focuses on fast adversarial training.
            </span>
            
        </td>
        <td class="catd">79.84%</td>
        <td class="aatd">43.93%</td>
        
        <td class="aa-extd">43.93%</td>
        <td class="flagsd">Unknown</td>
        
        <td class="datatd">&#215;</td>
        <td class="archtd">PreActResNet-18</td>
        <td class="venuetd">NeurIPS 2020</td>
    </tr>
    
    <tr>
        <td class="ranktd">45</td>
        <td class="methoddt">
            <a href="https://arxiv.org/abs/1905.10626" target="_blank">Rethinking Softmax Cross-Entropy Loss for Adversarial Robustness</a>
            
        </td>
        <td class="catd">80.89%</td>
        <td class="aatd">43.48%</td>
        
        <td class="aa-extd">43.48%</td>
        <td class="flagsd">Unknown</td>
        
        <td class="datatd">&#215;</td>
        <td class="archtd">ResNet-32</td>
        <td class="venuetd">ICLR 2020</td>
    </tr>
    
    <tr>
        <td class="ranktd">46</td>
        <td class="methoddt">
            <a href="https://arxiv.org/abs/2001.03994" target="_blank">Fast is better than free: Revisiting adversarial training</a>
            
            <br>
            <span class="td-footer">
                Focuses on fast adversarial training.
            </span>
            
        </td>
        <td class="catd">83.34%</td>
        <td class="aatd">43.21%</td>
        
        <td class="aa-extd">43.21%</td>
        <td class="flagsd">Unknown</td>
        
        <td class="datatd">&#215;</td>
        <td class="archtd">PreActResNet-18</td>
        <td class="venuetd">ICLR 2020</td>
    </tr>
    
    <tr>
        <td class="ranktd">47</td>
        <td class="methoddt">
            <a href="https://arxiv.org/abs/1904.12843" target="_blank">Adversarial Training for Free!</a>
            
        </td>
        <td class="catd">86.11%</td>
        <td class="aatd">41.47%</td>
        
        <td class="aa-extd">41.47%</td>
        <td class="flagsd">Unknown</td>
        
        <td class="datatd">&#215;</td>
        <td class="archtd">WideResNet-34-10</td>
        <td class="venuetd">NeurIPS 2019</td>
    </tr>
    
    <tr>
        <td class="ranktd">48</td>
        <td class="methoddt">
            <a href="https://openreview.net/forum?id=HkeryxBtPB" target="_blank">MMA Training: Direct Input Space Margin Maximization through Adversarial Training</a>
            
        </td>
        <td class="catd">84.36%</td>
        <td class="aatd">41.44%</td>
        
        <td class="aa-extd">41.44%</td>
        <td class="flagsd">Unknown</td>
        
        <td class="datatd">&#215;</td>
        <td class="archtd">WideResNet-28-4</td>
        <td class="venuetd">ICLR 2020</td>
    </tr>
    
    <tr>
        <td class="ranktd">49</td>
        <td class="methoddt">
            <a href="https://arxiv.org/abs/2011.03083" target="_blank">A Tunable Robust Pruning Framework Through Dynamic Network Rewiring of DNNs</a>
            
            <br>
            <span class="td-footer">
                Compressed model
            </span>
            
        </td>
        <td class="catd">87.32%</td>
        <td class="aatd">40.41%</td>
        
        <td class="aa-extd">40.41%</td>
        <td class="flagsd"><div class="flagsd-emoji">&#215;</div></td>
        
        <td class="datatd">&#215;</td>
        <td class="archtd">ResNet-18</td>
        <td class="venuetd">ASP-DAC 2021</td>
    </tr>
    
    <tr>
        <td class="ranktd">50</td>
        <td class="methoddt">
            <a href="https://arxiv.org/abs/1905.11911" target="_blank">Controlling Neural Level Sets</a>
            
            <br>
            <span class="td-footer">
                Uses \(\ell_{\infty} \) = 0.031 â‰ˆ 7.9/255 instead of 8/255.
            </span>
            
        </td>
        <td class="catd">81.30%</td>
        <td class="aatd">40.22%</td>
        
        <td class="aa-extd">40.22%</td>
        <td class="flagsd">Unknown</td>
        
        <td class="datatd">&#215;</td>
        <td class="archtd">ResNet-18</td>
        <td class="venuetd">NeurIPS 2019</td>
    </tr>
    
    <tr>
        <td class="ranktd">51</td>
        <td class="methoddt">
            <a href="http://openaccess.thecvf.com/content_CVPR_2019/html/Moosavi-Dezfooli_Robustness_via_Curvature_Regularization_and_Vice_Versa_CVPR_2019_paper" target="_blank">Robustness via Curvature Regularization, and Vice Versa</a>
            
        </td>
        <td class="catd">83.11%</td>
        <td class="aatd">38.50%</td>
        
        <td class="aa-extd">38.50%</td>
        <td class="flagsd">Unknown</td>
        
        <td class="datatd">&#215;</td>
        <td class="archtd">ResNet-18</td>
        <td class="venuetd">CVPR 2019</td>
    </tr>
    
    <tr>
        <td class="ranktd">52</td>
        <td class="methoddt">
            <a href="http://papers.nips.cc/paper/8459-defense-against-adversarial-attacks-using-feature-scattering-based-adversarial-training" target="_blank">Defense Against Adversarial Attacks Using Feature Scattering-based Adversarial Training</a>
            
        </td>
        <td class="catd">89.98%</td>
        <td class="aatd">36.64%</td>
        
        <td class="aa-extd">36.64%</td>
        <td class="flagsd">Unknown</td>
        
        <td class="datatd">&#215;</td>
        <td class="archtd">WideResNet-28-10</td>
        <td class="venuetd">NeurIPS 2019</td>
    </tr>
    
    <tr>
        <td class="ranktd">53</td>
        <td class="methoddt">
            <a href="https://openreview.net/forum?id=Syejj0NYvr&noteId=Syejj0NYvr" target="_blank">Adversarial Interpolation Training: A Simple Approach for Improving Model Robustness</a>
            
        </td>
        <td class="catd">90.25%</td>
        <td class="aatd">36.45%</td>
        
        <td class="aa-extd">36.45%</td>
        <td class="flagsd">Unknown</td>
        
        <td class="datatd">&#215;</td>
        <td class="archtd">WideResNet-28-10</td>
        <td class="venuetd">OpenReview, Sep 2019</td>
    </tr>
    
    <tr>
        <td class="ranktd">54</td>
        <td class="methoddt">
            <a href="http://openaccess.thecvf.com/content_ICCV_2019/html/Jang_Adversarial_Defense_via_Learning_to_Generate_Diverse_Attacks_ICCV_2019_paper.html" target="_blank">Adversarial Defense via Learning to Generate Diverse Attacks</a>
            
        </td>
        <td class="catd">78.91%</td>
        <td class="aatd">34.95%</td>
        
        <td class="aa-extd">34.95%</td>
        <td class="flagsd">Unknown</td>
        
        <td class="datatd">&#215;</td>
        <td class="archtd">ResNet-20</td>
        <td class="venuetd">ICCV 2019</td>
    </tr>
    
    <tr>
        <td class="ranktd">55</td>
        <td class="methoddt">
            <a href="https://openreview.net/forum?id=rJlf_RVKwr" target="_blank">Sensible adversarial learning</a>
            
        </td>
        <td class="catd">91.51%</td>
        <td class="aatd">34.22%</td>
        
        <td class="aa-extd">34.22%</td>
        <td class="flagsd">Unknown</td>
        
        <td class="datatd">&#215;</td>
        <td class="archtd">WideResNet-34-10</td>
        <td class="venuetd">OpenReview, Sep 2019</td>
    </tr>
    
    <tr>
        <td class="ranktd">56</td>
        <td class="methoddt">
            <a href="https://arxiv.org/abs/1906.06316" target="_blank">Towards Stable and Efficient Training of Verifiably Robust Neural Networks</a>
            
            <br>
            <span class="td-footer">
                Verifiably robust model with 32.24% provable robust accuracy
            </span>
            
        </td>
        <td class="catd">44.73%</td>
        <td class="aatd">32.64%</td>
        
        <td class="aa-extd">32.64%</td>
        <td class="flagsd">Unknown</td>
        
        <td class="datatd">&#215;</td>
        <td class="archtd">5-layer-CNN</td>
        <td class="venuetd">ICLR 2020</td>
    </tr>
    
    <tr>
        <td class="ranktd">57</td>
        <td class="methoddt">
            <a href="http://openaccess.thecvf.com/content_ICCV_2019/html/Wang_Bilateral_Adversarial_Training_Towards_Fast_Training_of_More_Robust_Models_ICCV_2019_paper.html" target="_blank">Bilateral Adversarial Training: Towards Fast Training of More Robust Models Against Adversarial Attacks</a>
            
        </td>
        <td class="catd">92.80%</td>
        <td class="aatd">29.35%</td>
        
        <td class="aa-extd">29.35%</td>
        <td class="flagsd">Unknown</td>
        
        <td class="datatd">&#215;</td>
        <td class="archtd">WideResNet-28-10</td>
        <td class="venuetd">ICCV 2019</td>
    </tr>
    
    <tr>
        <td class="ranktd">58</td>
        <td class="methoddt">
            <a href="https://arxiv.org/abs/1905.10510" target="_blank">Enhancing Adversarial Defense by k-Winners-Take-All</a>
            
            <br>
            <span class="td-footer">
                Uses \(\ell_{\infty} \) = 0.031 â‰ˆ 7.9/255 instead of 8/255.<br>7.40% robust accuracy is due to 1 restart of APGD-CE and 30 restarts of Square Attack<br>Note: <a href="https://arxiv.org/abs/2002.08347">this adaptive evaluation</a> (Section 5) reports 0.16% robust accuracy on a different model (adversarially trained ResNet-18).
            </span>
            
        </td>
        <td class="catd">79.28%</td>
        <td class="aatd">18.50%</td>
        
        <td class="aa-extd">7.40%</td>
        <td class="flagsd"><div class="flagsd-emoji">&#9745;</div></td>
        
        <td class="datatd">&#215;</td>
        <td class="archtd">DenseNet-121</td>
        <td class="venuetd">ICLR 2020</td>
    </tr>
    
    <tr>
        <td class="ranktd">59</td>
        <td class="methoddt">
            <a href="https://arxiv.org/abs/2003.04286" target="_blank">Manifold Regularization for Adversarial Robustness</a>
            
        </td>
        <td class="catd">90.84%</td>
        <td class="aatd">1.35%</td>
        
        <td class="aa-extd">1.35%</td>
        <td class="flagsd">Unknown</td>
        
        <td class="datatd">&#215;</td>
        <td class="archtd">ResNet-18</td>
        <td class="venuetd">arXiv, Mar 2020</td>
    </tr>
    
    <tr>
        <td class="ranktd">60</td>
        <td class="methoddt">
            <a href="https://arxiv.org/abs/1904.00887" target="_blank">Adversarial Defense by Restricting the Hidden Space of Deep Neural Networks</a>
            
        </td>
        <td class="catd">89.16%</td>
        <td class="aatd">0.28%</td>
        
        <td class="aa-extd">0.28%</td>
        <td class="flagsd">Unknown</td>
        
        <td class="datatd">&#215;</td>
        <td class="archtd">ResNet-110</td>
        <td class="venuetd">ICCV 2019</td>
    </tr>
    
    <tr>
        <td class="ranktd">61</td>
        <td class="methoddt">
            <a href="https://arxiv.org/abs/1912.10185" target="_blank">Jacobian Adversarially Regularized Networks for Robustness</a>
            
        </td>
        <td class="catd">93.79%</td>
        <td class="aatd">0.26%</td>
        
        <td class="aa-extd">0.26%</td>
        <td class="flagsd">Unknown</td>
        
        <td class="datatd">&#215;</td>
        <td class="archtd">WideResNet-34-10</td>
        <td class="venuetd">ICLR 2020</td>
    </tr>
    
    <tr>
        <td class="ranktd">62</td>
        <td class="methoddt">
            <a href="https://arxiv.org/abs/2006.07682" target="_blank">ClusTR: Clustering Training for Robustness
</a>
            
        </td>
        <td class="catd">91.03%</td>
        <td class="aatd">0.00%</td>
        
        <td class="aa-extd">0.00%</td>
        <td class="flagsd">Unknown</td>
        
        <td class="datatd">&#215;</td>
        <td class="archtd">WideResNet-28-10</td>
        <td class="venuetd">arXiv, Jun 2020</td>
    </tr>
    
    <tr>
        <td class="ranktd">63</td>
        <td class="methoddt">
            <a href="https://github.com/RobustBench/robustbench/" target="_blank">Standardly trained model</a>
            
        </td>
        <td class="catd">94.78%</td>
        <td class="aatd">0.0%</td>
        
        <td class="aa-extd">0.0%</td>
        <td class="flagsd">Unknown</td>
        
        <td class="datatd">&#215;</td>
        <td class="archtd">WideResNet-28-10</td>
        <td class="venuetd">N/A</td>
    </tr>
    
    </tbody>
</table>
<script>
    $(document).ready(function () {
        $("#cifar10_leaderboard_Linf").DataTable({
            lengthMenu: [15, 25, 50, 75, 100],
            "drawCallback": function (settings) {
                MathJax.Hub.Queue(["Typeset", MathJax.Hub]);
            },
            language: {
                searchPlaceholder: "Papers, architectures, venues"
            },
            
            columnDefs: [
                { width: "15%", targets: 4 },
                { width: "15%", targets: 5 }
            ]
            
        });
    });
</script>
